{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习回顾总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归、Logistic回归、KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 目标函数  损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目标函数优化方式：\n",
    "目标函数一般情况下都是凸函数，所以常用的方案是最小二乘和梯度下降，\n",
    "最小二乘：矩阵求逆\n",
    "梯度下降：批量梯度下降，随机梯度下降\n",
    "\n",
    "正则"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从数据中找出特征矩阵X和目标属性Y之间的线性关系，线性关系特指 未知变量的最高次项为1的关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 多项式拓展"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要的功能是将低维度空间数据映射到高维度空间\n",
    "\n",
    "(a,b)->(a,b,a^2,b^2,ab)  其中a,b为未知的特征变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 线性回归+多项式拓展"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 如果数据本身不是线性关系的，那么直接使用线性回归模型的效果不会太好-->产生欠拟合\n",
    "2. 如果在低维度空间中不是线性关系，但是如果将数据映射到高维度空间的时候，数据有可能变成线性关系，从而可以使用线性回归\n",
    "3. 如果映射的维度特别高，那么数据就会完全变成线性的，从而训练出来的模型会非常契合训练数据，但是实际上的数据可能会和训练数据存在一定的差距，从而可能导致在其他的数据集中的效果不好-->产生过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 过拟合的产生及表现形式："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 表现形式：在训练数据张表现效果非常好，但是在测试集上表现不佳\n",
    "2. 产生原因：进入算法模型训练的这个数据集特别契合算法模型，导致训练啊出来的模型非常完美，但是实际的数据一定存在训练数据与测试数据的不一致的地方，不一致性导致产生过拟合\n",
    "\n",
    "\n",
    "解决拟合的方法：L1-norm, L2-norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic 回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本质：二分类算法，计算样本X属于一个类别的概率为p,属于另外一个类别的概率为(1-p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SoftMax回归："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与Logistic回归的区别在于：softmax是一个多分类算法，需要计算样本属于某一个类别的概率，最终认为样本属于概率最大的那一个类别\n",
    "\n",
    "softMax实际上会为每一个类别训练出一个θ向量，所以在softmax中需要求解的参数其实是一个由k个向量组成的θ矩阵\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 模型持久化\n",
    "### 管道操作pipeLine\n",
    "### 模型效果评估\n",
    "### 交叉验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 交叉验证，训练集和测试集\n",
    "- 对数据集合进行划分\n",
    "- 对训练集进行训练集和验证集的划分，k折较差，可以选择k种不同训练集和验证集的的交叉验证\n",
    "- 选择k种模型中最好的那一个,（不同参数表示不同的模型）\n",
    "- 此外还有留一法等方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN回顾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
